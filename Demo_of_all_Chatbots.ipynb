{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWTwpVcAhEQl"
      },
      "source": [
        "# **AI Chatbots for Imaging Recommendations Aligned with ACR Guidelines**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTvJntMww5Ur"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index==0.5.0 -q\n",
        "!pip install gradio -q\n",
        "!pip install PyPDF2 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import gradio as gr\n",
        "import openai\n",
        "from llama_index import (\n",
        "    GPTSimpleVectorIndex,\n",
        "    LLMPredictor,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "# Set the OpenAI API key. If unsure about obtaining the API key, refer to https://platform.openai.com/account/api-keys for more information.\n",
        "# For estimating costs associated with index creation and chatbot usage, please visit: https://openai.com/pricing\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'your_api_key_here'\n",
        "\n",
        "\n",
        "# Set the folder path for ACR data and the rebuild index flag. This script doesn't include\n",
        "# importing ACR guidelines or a predefined index due to license restrictions on ACR guidelines.\n",
        "# For more information, refer to the guidelines on the ACR website.\n",
        "\n",
        "FOLDER_PATH = \"ACR\"\n",
        "REBUILD_INDEX = False\n",
        "\n",
        "def setup_index(folder_path, rebuild_index):\n",
        "    index_file_name = 'index_simple35.json'\n",
        "    \n",
        "    # Check if the folder path exists and contains PDF files\n",
        "    if not os.path.exists(folder_path) or not glob.glob(f\"{folder_path}/*.pdf\"):\n",
        "        print(\"The folder path either does not exist or does not contain PDF files.\")\n",
        "        return\n",
        "\n",
        "    # Rebuild the index if rebuild_index is True or the index file does not exist\n",
        "    if rebuild_index or not os.path.isfile(index_file_name):\n",
        "        # Load documents from the folder path\n",
        "        documents = SimpleDirectoryReader(folder_path).load_data()\n",
        "        \n",
        "        # Initialize the LLMPredictor with the ChatOpenAI model\n",
        "        llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=512, request_timeout=120))\n",
        "        \n",
        "        # Create a service context for the LLMPredictor\n",
        "        service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=512)\n",
        "        \n",
        "        # Create an index from the documents and save it to disk\n",
        "        index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\n",
        "        index.save_to_disk(index_file_name)\n",
        "\n",
        "def get_combined_chatbot_response(input_text):\n",
        "    # Format the input text\n",
        "    input_text = f'Case: {input_text} Question: Is imaging for this Usually Appropriate and if yes, state precisely only what imaging modality is the most Appropriate and if contrast agent is needed, do not mention \"May Be Appropriate\" or \"Usually Not Appropriate\".)'\n",
        "    \n",
        "    # Initialize the LLMPredictor with the ChatOpenAI model used in accGPT\n",
        "    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=512, request_timeout=120))\n",
        "    \n",
        "    # Create a service context for the LLMPredictor\n",
        "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=512)\n",
        "\n",
        "    # Load the index from disk\n",
        "    index = GPTSimpleVectorIndex.load_from_disk('index_simple35.json')\n",
        "    \n",
        "    # Define the messages to be sent to the models without index\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\"},\n",
        "        {\"role\": \"user\", \"content\": input_text},\n",
        "    ]\n",
        "\n",
        "    # accGPT approach: Query the index and get the response from Top 3 Text nodes using GPT-3.5-Turbo \n",
        "    response = index.query(input_text, response_mode=\"compact\", service_context=service_context, similarity_top_k=3)\n",
        "    output_accGPT = response.response.replace('\\n', '\\\\n')\n",
        "\n",
        "    # Get the response from GPT-3.5-Turbo\n",
        "    response35 = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages, timeout=120)\n",
        "    output35 = response35.choices[0].message['content'].replace('\\n', '\\\\n')\n",
        "    \n",
        "    # Get the response from GPT-4\n",
        "    response4 = openai.ChatCompletion.create(model=\"gpt-4\", messages=messages, timeout=120)\n",
        "    output4 = response4.choices[0].message['content'].replace('\\n', '\\\\n')\n",
        "    \n",
        "    # Combine the responses from all models\n",
        "    answer = f\"accGPT: {output_accGPT}\\n\\nGPT 3.5-Turbo: {output35}\\n\\nGPT 4: {output4}\"\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "def launch_interface(chatbot_function):\n",
        "    iface = gr.Interface(\n",
        "        fn=get_combined_chatbot_response,\n",
        "        inputs=[gr.Textbox(lines=7, label=\"Enter your case\")],\n",
        "        outputs=gr.Textbox(lines=7, label=\"Imaging Recommendations\"),\n",
        "        title=\"AI Chatbots for Imaging Recommendations Aligned with ACR Guidelines\"\n",
        "    )\n",
        "\n",
        "    # Launch the interface\n",
        "    iface.launch(share=True, debug=False)\n",
        "\n",
        "def main():\n",
        "    setup_index(FOLDER_PATH, REBUILD_INDEX)\n",
        "    launch_interface(get_combined_chatbot_response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "kFaXpZjieSV_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "0722a3a7-3aeb-4e84-bdef-ad057de66eed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder path either does not exist or does not contain PDF files.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://79524902c723a5af4e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://79524902c723a5af4e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}